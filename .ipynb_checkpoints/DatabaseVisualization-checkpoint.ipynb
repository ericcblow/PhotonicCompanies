{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726e61b1-f473-40a0-9bfe-b530b32d41f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "#!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009b3eb8-71e3-4518-bb4b-ed8e250ea480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_excel_data(file_path, sheet_name):\n",
    "    # Load the workbook and select the desired sheet\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook[sheet_name]\n",
    "\n",
    "    # Get labels from row 2 (B2 to G2)\n",
    "    labels = [sheet.cell(row=2, column=col).value for col in range(2, 8)]  # Columns B-G\n",
    "    # print(labels)\n",
    "    \n",
    "    # Check if all labels are present\n",
    "    if not all(labels):\n",
    "        raise ValueError(\"One or more labels in row 2 are missing.\")\n",
    "\n",
    "    # Initialize a dictionary to store the data for each label\n",
    "    data = {label: [] for label in labels}\n",
    "    \n",
    "    # Get data from rows starting at B3 (columns B-G)\n",
    "    for row in sheet.iter_rows(min_row=3, min_col=2, max_col=7, values_only=True):\n",
    "        for col_index, value in enumerate(row):\n",
    "            if value:  # Skip empty cells\n",
    "                data[labels[col_index]].append(value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d794b92f-ca18-4ae9-ac64-893162eedd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company Name': ['LightMatter', 'Lightelligence', 'Ayar Labs', 'PsiQuantum', 'Quantum Transistors', 'Q.ANT', 'Lumai ', 'iPRONICS', 'Salience Labs', 'Pixel Photonics', 'Dream Photonics ', 'Akhetonics', 'Celestial AI', 'Xscape Photonics', 'Optelligence', 'Nubis Communications', 'Voyant Photonics', 'Aegiq', 'Nu-quantum', 'Miraex', 'Nordic Quantum Computing Group', 'Orca Computing', 'Photonic Inc', 'Quandela ', 'Quix', 'Sparrow Quantum', 'Lumiphase', 'Enosemi', 'Nexus Photonics', 'Black Semiconductor'], 'Size': [200, 200, '200+', 280, 50, 100, 20, '< 50', '< 50', '< 50', 10, '< 50', '< 200', '< 50', '< 3', '< 50 ', '< 30', '< 50 ', '< 50 ', 50, 'CLOSED 11/2024', '~100', '< 50', '< 50', '< 50', '< 50 ', '< 100 ', '< 50 ', '< 20 ', '<200'], 'Focus': ['Optical MVM / PNN', 'Optical MVM / Networking', 'Optical I/O for AI, Interconnection ', 'Quantum Computing / Optical Interconnect', 'solid-state\\xa0quantum\\xa0processor', 'Optical MVM', '3D optical AI computing ', 'Microwave Photonics and Networking', 'silicon photonic solutions that will solve the challenge the growth in AI', 'Superconducting Nanowire Single Photon Detectors (SNSPD) and Quantum Computing', 'Packaging and Layout Design; world’s best chipsets for integrated photonics', 'Neuromorphic, Quantum, Analog, Digital, ADC', 'Photonic Fabric (Networking for AI)', 'photonics solutions that enable the next generation of AI, ML, and simulation hardware.', 'Photonic AI ', 'Co-Packaged Optics, Pluggable Transceivers, Active Optical Cables', 'LiDAR', 'Full Stack Quantum Computing', 'Photonic-Enabled Quantum Computing', 'photonic and quantum solutions for next-generation sensing, networking and computing', 'CLOSED 11/2024', 'error-corrected photonic quantum computers', 'Silicon photonic Quantum Computing', 'Silicon photonic Quantum Computing', 'photonic quantum processor based upon silicon nitride waveguides', 'photonic quantum technology components', 'Optical interconnects and computing using Si Ph and BTO', 'Photonic-Electronic Design IP and Custom Silicon', 'Advanced heterogeneous integration, SiN, GaAs, GaN, InP', '2D material graphene to create ultra-fast, energy-efficient, and scalable chip fabrics'], 'CEO/Founders/Affliation': ['Nick Harris, Dirk Englund, David Miller, MIT, Stanford', 'Yichen Shen, MIT ', 'Mark Wade', \"Jeremy O'Brien;\\xa0Terry Rudolph;\\xa0Peter Shadbolt; Mark Thompson\", 'Shmuel Bachinsky', 'Michael Förtsch, TRUMPF Photonics', 'James Spall, University of Oxford', 'Jose Capmany', 'Oxford, Harish Bhaskaran and Wolfram Pernice', 'Wolfram Pernice', 'Lukas Chrostowski', 'David Lazovsky', 'Vivek Raghunathan, Michal Lipson, Keren Bergman, Columbia', 'Volker J. Sorger', 'Peter Winzer, Bell Labs', 'Steven Miller, Michel Lipson', 'Scott Dufferwiel, Univ. of Sheffield', 'Dr. Carmen Palacios-Berraquero, University of Cambridge', 'Nicolas Abelé, Karel Dumon and Clément Javerzac-Galy, Miraex, EPFL ', 'CLOSED 11/2024', 'Professor Ian Walmsley, Josh Nunn, Richard Murray, University of Oxford', 'Paul Terry, Stephanie Simmons, Simon Fraser University', 'Centre for Nanoscience and Nanotechnology', 'Hans van den Vlekkert, University of Twente', 'Peter Lodahl, Niels Bohr Institute Quantum Photonics Lab', 'Stefan Abel, BTO Modulator Author,  started by IBM Si Ph people', 'Matt Streshinsky, Came out of Lumious Computing'], 'Location ': ['Mountain View, CA and Toronto, Canada, and Boston, MA', 'Boston, MA', 'San Jose, CA', 'Palo Alto, CA', 'Tel Aviv, Israel and NYC, US', 'Stuttgart, Germany', 'Oxford, England', 'Valencia, Spain', 'Oxford, England', 'Germany', 'Vancover, BC, Canada', 'Berlin, Germany', 'Santa Clara, CA, USA', 'NY, USA', 'Austin, USA', 'Murray Hill, New Jersey, USA', 'New York, NY 10018', 'Sheffield, England', 'Cambridge, UK', 'Écublens, Vaud, Switzerland', 'Oslo, Norway ', 'London, Toronto, Austin', 'Vancouver, Canada', 'Massy, Île-de-France', 'Ulm, Germany and Stuttgart Germany, and Amsterdam, Netherlands, and Enschede, Netherlands', 'Copenhagen, Denmark', 'Zurich, Switzerland', 'California,USA', 'Goleta, California, USA', 'Aachen, Germany'], 'Notes': ['HT works here. ', 'Nvidia, Intel, AMD investors', 'HT used to work here', 'Thomas works here', 'XPU, raised 6.3 M USD ', 'Sara and Siamik work/worked here', 'CLOSED 11/2024']}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = './Photonic Companies.xlsx'  # Replace with your Excel file path\n",
    "sheet_name = 'Startup'  # Replace with the name of the sheet\n",
    "\n",
    "try:\n",
    "    data_SU = import_excel_data(file_path, sheet_name)\n",
    "    print(data_SU)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992f9d63-498d-4af5-965d-36ef0ca6c7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company Name': ['Nvidia', 'Google ', 'NEC', 'Intel ', 'Universal Display Corporation', 'OpenAI', 'Apple', 'AMD', 'Cisco', 'Luxtera', 'Infinera ', 'NeoPhotonics', 'Coherent Inc. ', 'Hamamatsu Corporation', 'M Squared\\xa0', 'NTT', 'IBM', 'Synopsys Photonic Solutions'], 'Size': [500, 100], 'Focus': ['quantum technology, biophotonics, and chemical sensing'], 'CEO/Founders/Affliation': ['GRAEME MALCOLM OBE, Strathclyde University'], 'Location ': ['NJ, USA and Japan', 'Glasgow and London and Palo Alto and  Boston and Berlin', 'Zurich, Switzerland', 'Mountain View, California'], 'Notes': []}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = './Photonic Companies.xlsx'  # Replace with your Excel file path\n",
    "sheet_name = 'Large Company'  # Replace with the name of the sheet\n",
    "\n",
    "try:\n",
    "    data_LC = import_excel_data(file_path, sheet_name)\n",
    "    print(data_LC)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba18db43-69da-46a7-a641-94178ecdc28c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company Name': ['Global Foundries', 'AIM ', 'AMF ', 'HHI ', 'Smart Photonics', 'LionX', 'Tower', 'LIGENTEC', 'VTT', 'IMEC'], 'Size': [], 'Focus': [], 'CEO/Founders/Affliation': ['Michael Geiselmann, Michael Zervas,  Tobias Kippenberg,  EPFL '], 'Location ': ['Vaud, Switzerland'], 'Notes': []}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = './Photonic Companies.xlsx'  # Replace with your Excel file path\n",
    "sheet_name = 'Foundries'  # Replace with the name of the sheet\n",
    "\n",
    "try:\n",
    "    data_F = import_excel_data(file_path, sheet_name)\n",
    "    print(data_F)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979d4eba-50eb-4cd6-a425-53bcc01d1a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company Name': ['Bascom Hunter', 'Photonic Systems Inc', 'Phase Sensitive Innovations', 'Honeywell'], 'Size': ['< 100', '< 100', '< 100'], 'Focus': ['Microwave Photonics, Neuromorphioc Photonics', 'Microwave Photonics, Interference Cancellation', 'Microwave Photonics, Diffractive Optics, Phase Arrays, Thin Film LiNo'], 'CEO/Founders/Affliation': ['Paul R. Prucnal , Andy McCandless', 'Charles Cox, Edward Ackerman', 'Dennis Prather, Univ of Delware '], 'Location': ['Baton Rouge, LA'], 'Notes': []}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = './Photonic Companies.xlsx'  # Replace with your Excel file path\n",
    "sheet_name = 'Defense Contractors'  # Replace with the name of the sheet\n",
    "\n",
    "try:\n",
    "    data_DC = import_excel_data(file_path, sheet_name)\n",
    "    print(data_DC)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff4b48a-3da1-4767-880f-4a22a04fab12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Rough Location to longitude and latitude\n",
    "def get_coordinates(locations):\n",
    "    # Initialize geolocator\n",
    "    geolocator = Nominatim(user_agent=\"location_to_coordinates\")\n",
    "\n",
    "    # Dictionary to store results\n",
    "    coordinates = {}\n",
    "\n",
    "    for location in locations:\n",
    "        try:\n",
    "            # Get location details\n",
    "            loc = geolocator.geocode(location)\n",
    "            if loc:\n",
    "                coordinates[location] = (loc.latitude, loc.longitude)\n",
    "            else:\n",
    "                coordinates[location] = None  # No result found\n",
    "        except GeocoderTimedOut:\n",
    "            coordinates[location] = None  # Handle timeout\n",
    "\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b15749-330d-4de9-ba07-03447ff06782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston, MA, USA: Latitude = 42.3554334, Longitude = -71.060511\n",
      "New York, NY, USA: Latitude = 40.7127281, Longitude = -74.0060152\n",
      "San Francisco, CA, USA: Latitude = 37.7792588, Longitude = -122.4193286\n"
     ]
    }
   ],
   "source": [
    "# Example list of locations\n",
    "locations = [\"Boston, MA, USA\", \"New York, NY, USA\", \"San Francisco, CA, USA\"]\n",
    "\n",
    "# Get coordinates\n",
    "coordinates = get_coordinates(locations)\n",
    "\n",
    "# Print results\n",
    "for location, coord in coordinates.items():\n",
    "    if coord:\n",
    "        print(f\"{location}: Latitude = {coord[0]}, Longitude = {coord[1]}\")\n",
    "    else:\n",
    "        print(f\"{location}: Coordinates not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6312641-e84e-440c-8091-21ce1e81f0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Company Name', 'Size', 'Focus', 'CEO/Founders/Affliation', 'Location ', 'Notes']) \n",
      "\n",
      "['Mountain View, CA and Toronto, Canada, and Boston, MA', 'Boston, MA', 'San Jose, CA', 'Palo Alto, CA', 'Tel Aviv, Israel and NYC, US', 'Stuttgart, Germany', 'Oxford, England', 'Valencia, Spain', 'Oxford, England', 'Germany', 'Vancover, BC, Canada', 'Berlin, Germany', 'Santa Clara, CA, USA', 'NY, USA', 'Austin, USA', 'Murray Hill, New Jersey, USA', 'New York, NY 10018', 'Sheffield, England', 'Cambridge, UK', 'Écublens, Vaud, Switzerland', 'Oslo, Norway ', 'London, Toronto, Austin', 'Vancouver, Canada', 'Massy, Île-de-France', 'Ulm, Germany and Stuttgart Germany, and Amsterdam, Netherlands, and Enschede, Netherlands', 'Copenhagen, Denmark', 'Zurich, Switzerland', 'California,USA', 'Goleta, California, USA', 'Aachen, Germany'] \n",
      "\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# if company has multiple locations \n",
    "# key word \"and\" \n",
    "print(data_SU.keys(),'\\n')\n",
    "print(data_SU[\"Location \"], '\\n')\n",
    "print(len(data_SU[\"Location \"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb27b6ad-39ac-47f6-b998-7ceb3c7b4da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_and_split(Locations, keyword):\n",
    "    results = []\n",
    "    split_strings = []\n",
    "    NewLocations = []\n",
    "    Indx2Dup = []\n",
    "    NewLocations = Locations\n",
    "    for idx, string in enumerate(Locations):\n",
    "        print(idx)\n",
    "        start_idx = string.find(keyword)\n",
    "        if start_idx != -1:  # Keyword found\n",
    "            end_idx = start_idx + len(keyword) - 1\n",
    "            results.append((idx, start_idx, end_idx))\n",
    "\n",
    "            # Split the string into two parts: before and after the keyword\n",
    "            before_keyword = string[:start_idx].strip()\n",
    "            after_keyword = string[end_idx + 1:].strip()\n",
    "            split_strings.append((before_keyword, after_keyword))\n",
    "            \n",
    "            # Append and replace new split string into original list\n",
    "            # Conditionals are to look for blank spaces or punctions and not include them \n",
    "            threshold = 2\n",
    "            if len(before_keyword) > threshold and len(after_keyword) > threshold:\n",
    "                # print(len(NewLocations))\n",
    "                # print(idx)\n",
    "                NewLocations[idx] = before_keyword\n",
    "                NewLocations.insert(idx+1, after_keyword)\n",
    "                #idx is no longer real as New List grows, need to keep track\n",
    "                Indx2Dup.append(idx) \n",
    "                #When duplicating the rows if there are consecutive number dup from \n",
    "                    # row - number of consecutive numbers\n",
    "                \n",
    "            if len(before_keyword) <= threshold and len(after_keyword) > threshold:\n",
    "                # print(len(NewLocations))\n",
    "                # print(idx)\n",
    "                NewLocations[idx] = after_keyword\n",
    "                \n",
    "            if len(before_keyword) > threshold and len(after_keyword) <= threshold:\n",
    "                # print(len(NewLocations))\n",
    "                # print(idx)\n",
    "                NewLocations[idx] = before_keyword            \n",
    "\n",
    "                \n",
    "    return results, split_strings, NewLocations, Indx2Dup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b2906f6-1311-40e9-88d3-64fdfdb9eede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "\n",
      "Split Strings:\n",
      "Original String Index: 0\n",
      "Before: 'This is a sample string'\n",
      "After: 'it contains and perhaps denver and.'\n",
      "Original String Index: 1\n",
      "Before: 'it contains'\n",
      "After: 'perhaps denver and.'\n",
      "Original String Index: 2\n",
      "Before: 'perhaps denver'\n",
      "After: '.'\n",
      "Original String Index: 4\n",
      "Before: ''\n",
      "After: 'is a conjunction.'\n",
      "Original String Index: 6\n",
      "Before: 'But maybe here'\n",
      "After: 'there'\n",
      "\n",
      "Result\n",
      "['This is a sample string', 'it contains', 'perhaps denver', 'Another example without the keyword.', 'is a conjunction.', 'Nothing here or here', 'But maybe here', 'there']\n"
     ]
    }
   ],
   "source": [
    "# Testing new search and split function\n",
    "strings = [\n",
    "    \"This is a sample string and it contains and perhaps denver and.\",\n",
    "    \"Another example without the keyword.\",\n",
    "    \"and is a conjunction.\",\n",
    "    \"Nothing here or here\",\n",
    "    \"But maybe here and there\"\n",
    "]\n",
    "\n",
    "# # Search for the keyword \"and\" and split strings\n",
    "# keyword = \"and\" # and is in Netherlands hahaha\n",
    "# matches, splits, nLocations, Indx = search_and_split(strings, keyword)\n",
    "\n",
    "keyword = \" and \"\n",
    "matches, splits, nLocations, Indx = search_and_split(data_SU[\"Location \"], keyword)\n",
    "\n",
    "# # Print results\n",
    "# print(\"Keyword Matches (Start and End Indices):\")\n",
    "# for match in matches:\n",
    "#     print(f\"String index: {match[0]}, Start index: {match[1]}, End index: {match[2]}\")\n",
    "\n",
    "\n",
    "print(\"\\nSplit Strings:\")\n",
    "for idx, (before, after) in enumerate(splits):\n",
    "    print(f\"Original String Index: {matches[idx][0]}\")\n",
    "    print(f\"Before: '{before}'\")\n",
    "    print(f\"After: '{after}'\")\n",
    "    \n",
    "# print(\"\\nResult\")\n",
    "# print(nLocations)\n",
    "\n",
    "print(\"\\nLocation List:\")\n",
    "print(data_SU[\"Location \"])\n",
    "    \n",
    "print(\"\\nNew Location List:\")\n",
    "print(nLocations)\n",
    "\n",
    "print(\"\\nIndex to Duplicate\")\n",
    "print(Indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a03114-c13a-4023-9073-ec9c2e94890b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mountain View, CA and Toronto, Canada, and Boston, MA',\n",
       " 'Boston, MA',\n",
       " 'San Jose, CA',\n",
       " 'Palo Alto, CA',\n",
       " 'Tel Aviv, Israel and NYC, US',\n",
       " 'Stuttgart, Germany',\n",
       " 'Oxford, England',\n",
       " 'Valencia, Spain',\n",
       " 'Oxford, England',\n",
       " 'Germany',\n",
       " 'Vancover, BC, Canada',\n",
       " 'Berlin, Germany',\n",
       " 'Santa Clara, CA, USA',\n",
       " 'NY, USA',\n",
       " 'Austin, USA',\n",
       " 'Murray Hill, New Jersey, USA',\n",
       " 'New York, NY 10018',\n",
       " 'Sheffield, England',\n",
       " 'Cambridge, UK',\n",
       " 'Écublens, Vaud, Switzerland',\n",
       " 'Oslo, Norway ',\n",
       " 'London, Toronto, Austin',\n",
       " 'Vancouver, Canada',\n",
       " 'Massy, Île-de-France',\n",
       " 'Ulm, Germany and Stuttgart Germany, and Amsterdam, Netherlands, and Enschede, Netherlands',\n",
       " 'Copenhagen, Denmark',\n",
       " 'Zurich, Switzerland',\n",
       " 'California,USA',\n",
       " 'Goleta, California, USA',\n",
       " 'Aachen, Germany']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_SU[\"Location \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc5aa8e8-dfe5-4d9a-8693-4d272c9d1271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Mountain View, CA and Toronto, Canada, and Boston, MA\n",
      "1\n",
      "Boston, MA\n",
      "2\n",
      "San Jose, CA\n",
      "3\n",
      "Palo Alto, CA\n",
      "4\n",
      "Tel Aviv, Israel and NYC, US\n",
      "5\n",
      "Stuttgart, Germany\n",
      "6\n",
      "Oxford, England\n",
      "7\n",
      "Valencia, Spain\n",
      "8\n",
      "Oxford, England\n",
      "9\n",
      "Germany\n",
      "10\n",
      "Vancover, BC, Canada\n",
      "11\n",
      "Berlin, Germany\n",
      "12\n",
      "Santa Clara, CA, USA\n",
      "13\n",
      "NY, USA\n",
      "14\n",
      "Austin, USA\n",
      "15\n",
      "Murray Hill, New Jersey, USA\n",
      "16\n",
      "New York, NY 10018\n",
      "17\n",
      "Sheffield, England\n",
      "18\n",
      "Cambridge, UK\n",
      "19\n",
      "Écublens, Vaud, Switzerland\n",
      "20\n",
      "Oslo, Norway \n",
      "21\n",
      "London, Toronto, Austin\n",
      "22\n",
      "Vancouver, Canada\n",
      "23\n",
      "Massy, Île-de-France\n",
      "24\n",
      "Ulm, Germany and Stuttgart Germany, and Amsterdam, Netherlands, and Enschede, Netherlands\n",
      "25\n",
      "Copenhagen, Denmark\n",
      "26\n",
      "Zurich, Switzerland\n",
      "27\n",
      "California,USA\n",
      "28\n",
      "Goleta, California, USA\n",
      "29\n",
      "Aachen, Germany\n"
     ]
    }
   ],
   "source": [
    "for idx, string in enumerate(data_SU[\"Location \"]):\n",
    "    print(idx)\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32be4a0-c69c-4e06-aba2-0fd2dea1ee84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
